---
title: "Do Scandals and Shocks Affect Elections?"
author: "Janet Hernandez"
date: "2022-10-24"
slug: "week7-shocks"
---

# Shocks and Election Impact #

This week, I will be doing the first blog extension. I will be replicating the Dobbs NYT example from section, but with the shock of recent inflation news. I predict that rising coverage on the state of the economy and inflation would have a negative affect on the President's party (Democrats) for generic ballot support. I am unsure whether or not this would also translate to an increase in support for Republicans but I am certain that I predict to see some hesitation towards Democrats due to economic inflation and market performances. I will be using the NYT developer API to source my data for news coverage. 

• Natural disaster: Shark attack (Achen and Bartels 2017), tornado
(Healy and Malhotra 2010) ⇝ decreased support for incumbents
• Sports (Healy, Mo, Malhotra 2010): college football team losing
their game ⇝ decreased support for incumbents
• Lottery (Bagues and Esteve-Volart 2016): Towns winning Spanish
Christmas lottery ⇝ increased support for incumbents

Global comparison (Powell & Whitten 1993): Punish only when
the gov’t is doing worse than other gov’ts
• Ex: the speed of recovery

I will also try to modify and revise my existing predictive model from week 6. 

```{r setup, include=FALSE}
library(dotenv)
library(jsonlite)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(plotly)
library(scales)
library(rjson)
library(jtools)
library(htmlwidgets)
library(reactable)
library(sqldf)
library(blogdown)
library(ggthemes)

# load up hidden api key
article_api <- "3tPdNNFHIqqJySrXcFHjvgaFeCIac11M"
semantic_api <- Sys.getenv("SEMANTIC_API")
# 
# # set base url
base_url_art <- "http://api.nytimes.com/svc/search/v2/articlesearch.json?q="
base_url_sem <- "http://api.nytimes.com/svc/semantic/v2/concept/name"
# 
# # set parameters
term <- "inflation"
facet_field <- "day_of_week"
facet <- "true"
fq <- "&fq=glocation='United States'"
begin_date <- "20220101"
end_date <- "20221022"
# 

complete_url <-paste0(base_url_art,fq =term,"&facet_field=",facet_field,"&facet=",facet,"&begin_date=",begin_date,"&end_date=",end_date,"&api-key=",article_api,sep = "")
# 
# # import dataset to R
sus <- jsonlite::fromJSON(complete_url)
# 
# # view how many hits
sus$response$meta$hits
# 
hits <- sus$response$meta$hits
cat("There were ",hits," hits for the search term 'inflation' during 2022 to date",sep = "")
# 
max_pages <- round((hits / 10) - 1)

# # store all pages in list
pages <- list()

# # trying again - WORKS!!!
# sus0 <- fromJSON(paste0(complete_url, "&page=0"), flatten = TRUE)
 #nrow(sus0$response$docs)
# sus1 <- fromJSON(paste0(complete_url, "&page=1"), flatten = TRUE)
# nrow(sus1$response$docs)
# sus2 <- fromJSON(paste0(complete_url, "&page=2"), flatten = TRUE)
# nrow(sus2$response$docs)

# organizations <- rbind_pages(
#   list(sus0$response$docs, sus1$response$docs, sus2$response$docs)
# )
 #nrow(organizations)
# 
 pages <- list()
 
 Sys.sleep(1) 
 for(i in 0:50){
   mydata <- jsonlite::fromJSON(paste0(complete_url, "&page=", i))
   message("Retrieving page ", i)
   pages[[i+1]] <- mydata$response$docs
   Sys.sleep(6) 
 }

# #combine all into one
organizations <- rbind_pages(pages)
# 
# #check output
nrow(organizations)
# 
colnames(organizations)

# 
# #check output
nrow(mydata)
# 
# # save df
saveRDS(organizations, file = "inflation_2022.RDS")

# reload
mydata <- readRDS("inflation_2022.RDS")

# check colnames
colnames(mydata)
```


```{r visualization, include=FALSE}
# visualization by month
library(dplyr)
month <- mydata %>% 
  group_by(month = month(pub_date, label = T)) %>% 
  dplyr::summarize(count = n()) %>% 
  ggplot(aes(month, count, group = 1, color = count)) +
    geom_line() +
    labs(y = "Article Count", x = "",
         title = "NYT Articles mentioning inflation in the US in 2022",
         color = "")

month
# visualization by day
day <- mydata %>% 
  group_by(month_day = paste0(month(pub_date, label = T),
           day = day(pub_date))) %>% 
  dplyr::summarize(count = n()) %>% 
  ggplot(aes(month_day, count, group = 1, color = count)) +
    geom_line() +
    labs(y = "Article Count", x = "",
         title = "NYT Articles mentioning inflation in the US in 2022",
         color = "")
day
# how about visualization by week
# extract raw date
mydata <- mydata %>% 
  mutate(publ_date = substr(pub_date, 1, 10))

# mutate week variable
mydata <- mydata %>% 
  mutate(week = strftime(publ_date, format = "%V"))
```

```{r, plot for inflation mentions}
# plot
mydata %>% 
  group_by(week) %>% 
  dplyr::summarize(count = n()) %>% 
  ggplot(aes(week, count, group = 1, color = count)) +
  geom_line() +
    labs(y = "Article Count", x = "Week",
         title = "NYT Articles Mentioning Inflation in the US in 2022",
         color = "")  

```



## Peak Inflation Coverage Lines Up With Unexpected Shift


```{r, generic ballot plot}
#now comparing this to generic ballot
X538_generic_ballot_averages_2018_2022 <- read.csv("~/Downloads/Section data/drive-download-20220922T150729Z-001/538_generic_ballot_averages_2018-2022.csv")


gb <- X538_generic_ballot_averages_2018_2022

# convert dat
gb <- gb %>%
  mutate(date_ = mdy(date)) %>%
  mutate(year = substr(date_, 1, 4)) %>%
  filter(year == 2022) %>%
  mutate(week = strftime(date_, format = "%V")) # Jan 1 looks weird 

 #get avg by party and week
dem <- gb %>%
  filter(candidate == 'Democrats')
x <- plyr::ddply(dem, .(week), function(z) mean(z$pct_estimate))
x$candidate <- c('Democrats')
x$avg_dem <- x$V1
x <- x %>%
   select(-V1)
x$avg_dem <-  round(x$avg_dem , digits = 1)
#
#
rep <- gb %>%
   filter(candidate == 'Republicans')
y <- plyr::ddply(rep, .(week), function(z) mean(z$pct_estimate))
y$candidate <- c('Republicans')
y$avg_rep <- y$V1
y <- y %>%
  select(-V1)
y$avg_rep <-  round(y$avg_rep, digits = 1)
#
#put all data frames into list
df_list <- list(gb, x, y)
#
# #merge all data frames together
polls_df <- df_list %>% reduce(full_join, by=c("candidate", "week"))
#
# # remove NAs
polls_df[] <-  t(apply(polls_df, 1, function(x) c(x[!is.na(x)], x[is.na(x)])))
#
polls_df <- polls_df %>%
   select(-avg_rep)
#
polls_df$avg_support <- polls_df$avg_dem
#
polls_df <- polls_df %>%
  select(-avg_dem)
#
# # keep only unique dates
polls_df <- polls_df %>%
   distinct(cycle, week, date_, avg_support, candidate) %>%
   filter(week != 52)

# visualize polls
my_colors <- c("blue", "red")
scale_color_manual(values = my_colors)

ballotsupport <- polls_df %>%
  group_by(candidate == 'Democrats') %>%
  mutate(date_ = as.Date(date_, format = '%Y-%m-%d')) %>%
  ggplot(aes(x = week, y = avg_support,
             colour = candidate)) +
  scale_color_manual(values = my_colors)+
   geom_line(aes(group=candidate), size = 0.3) + geom_point(size = 0.3) +
     #scale_x_date(date_labels = "%m, %Y") +
   ylab("generic ballot support") + xlab("") +
    theme_fivethirtyeight() +
geom_segment(x=("31"), xend=("31"),y=0,yend=30, lty=2, color="purple", alpha=0.4) + 
  annotate("text", x=("31"), y=31, label="Peak Inflation Coverage", size=5) 

ggplotly(ballotsupport)
```

